{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac616260",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlgb\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgb\u001b[39;00m \u001b[38;5;66;03m# Opsional, jika ingin mencoba XGBoost juga\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     16\u001b[39m warnings.filterwarnings(\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;66;03m# Mengabaikan peringatan untuk kebersihan output\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb # Opsional, jika ingin mencoba XGBoost juga\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Mengabaikan peringatan untuk kebersihan output\n",
    "\n",
    "# --- Langkah 1: Eksplorasi Data (EDA) & Pemahaman Masalah ---\n",
    "\n",
    "# Memuat Data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Simpan ID untuk submission nanti\n",
    "train_ID = train_df['Id']\n",
    "test_ID = test_df['Id']\n",
    "\n",
    "# Hapus kolom ID karena tidak berguna untuk prediksi\n",
    "train_df.drop(\"Id\", axis = 1, inplace = True)\n",
    "test_df.drop(\"Id\", axis = 1, inplace = True)\n",
    "\n",
    "print(f\"Ukuran data Train: {train_df.shape}\")\n",
    "print(f\"Ukuran data Test: {test_df.shape}\")\n",
    "\n",
    "# Analisis Target Variable ('SalePrice')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['SalePrice'], kde=True)\n",
    "plt.title('Distribusi SalePrice (Original)')\n",
    "plt.show()\n",
    "\n",
    "print(\"Skewness SalePrice: %f\" % train_df['SalePrice'].skew())\n",
    "print(\"Kurtosis SalePrice: %f\" % train_df['SalePrice'].kurt())\n",
    "\n",
    "# --- Langkah 3 Awal: Transformasi Target ---\n",
    "# Karena RMSLE adalah metriknya dan distribusinya miring, log transform adalah ide bagus.\n",
    "train_df[\"SalePrice\"] = np.log1p(train_df[\"SalePrice\"])\n",
    "y_train = train_df[\"SalePrice\"] # Simpan target\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['SalePrice'], kde=True)\n",
    "plt.title('Distribusi SalePrice (Log Transformed)')\n",
    "plt.show()\n",
    "\n",
    "# Gabungkan train dan test untuk preprocessing yang konsisten\n",
    "ntrain = train_df.shape[0]\n",
    "ntest = test_df.shape[0]\n",
    "all_data = pd.concat((train_df.drop(['SalePrice'], axis=1), test_df)).reset_index(drop=True)\n",
    "print(f\"Ukuran data gabungan: {all_data.shape}\")\n",
    "\n",
    "# --- Langkah 3 Lanjutan: Preprocessing & Cleaning ---\n",
    "\n",
    "# Penanganan Missing Values\n",
    "# Cek persentase missing values\n",
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "print(\"\\nFitur dengan Missing Values Terbanyak:\")\n",
    "print(missing_data.head(20))\n",
    "\n",
    "# Imputasi berdasarkan makna fitur (Contoh sederhana)\n",
    "# Kategori: NaN sering berarti 'None' atau tidak ada fitur tsb\n",
    "for col in ('PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu',\n",
    "            'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "            'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "            'MasVnrType'):\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "\n",
    "# Numerik: NaN bisa berarti 0 jika terkait fitur kategorikal 'None'\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars',\n",
    "            'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF',\n",
    "            'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea'):\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "# Lainnya: Imputasi dengan modus (kategorikal) atau median (numerik)\n",
    "all_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
    "all_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\n",
    "all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\n",
    "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n",
    "all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n",
    "# LotFrontage mungkin berhubungan dengan Neighborhood, imputasi median per Neighborhood\n",
    "all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Cek lagi apakah masih ada NaN\n",
    "print(f\"\\nJumlah NaN setelah imputasi: {all_data.isnull().sum().sum()}\")\n",
    "\n",
    "# --- Langkah 4: Feature Engineering (Contoh Sederhana) ---\n",
    "\n",
    "# Beberapa fitur numerik sebenarnya kategorikal\n",
    "all_data['MSSubClass'] = all_data['MSSubClass'].astype(str)\n",
    "all_data['OverallCond'] = all_data['OverallCond'].astype(str)\n",
    "all_data['YrSold'] = all_data['YrSold'].astype(str)\n",
    "all_data['MoSold'] = all_data['MoSold'].astype(str)\n",
    "\n",
    "# Membuat fitur total luas\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "\n",
    "# Transformasi fitur numerik yang miring (skewed)\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "print(\"\\nSkewness fitur numerik sebelum transformasi:\")\n",
    "print(skewness.head(10))\n",
    "\n",
    "skewness = skewness[abs(skewness['Skew']) > 0.75] # Ambil fitur yang sangat miring\n",
    "print(f\"Transformasi Box-Cox pada {skewness.shape[0]} fitur numerik\")\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15 # Parameter lambda untuk Box-Cox\n",
    "for feat in skewed_features:\n",
    "    # all_data[feat] += 1e-6 # Tambahkan nilai kecil jika ada 0, jika diperlukan Box-Cox\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)\n",
    "\n",
    "# --- Langkah 3 Akhir: Encoding Kategorikal ---\n",
    "print(f\"\\nBentuk data sebelum One-Hot Encoding: {all_data.shape}\")\n",
    "all_data = pd.get_dummies(all_data)\n",
    "print(f\"Bentuk data setelah One-Hot Encoding: {all_data.shape}\")\n",
    "\n",
    "# Pisahkan kembali data train dan test\n",
    "train_final = all_data[:ntrain]\n",
    "test_final = all_data[ntrain:]\n",
    "print(f\"Ukuran data Train Final: {train_final.shape}\")\n",
    "print(f\"Ukuran data Test Final: {test_final.shape}\")\n",
    "\n",
    "\n",
    "# --- Langkah 2 & 5: Strategi Validasi & Model Baseline (LightGBM) ---\n",
    "\n",
    "# Mendefinisikan fungsi evaluasi RMSLE (karena target sudah di-log)\n",
    "# Kita bisa pakai MSE langsung pada target log, lalu ambil akar kuadratnya.\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42).get_n_splits(train_final.values)\n",
    "    # Gunakan neg_mean_squared_error karena cross_val_score memaksimalkan score\n",
    "    rmse = np.sqrt(-cross_val_score(model, train_final.values, y_train,\n",
    "                                     scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)\n",
    "\n",
    "# Model LightGBM (Parameter awal, belum di-tuning)\n",
    "lgbm = lgb.LGBMRegressor(objective='regression',\n",
    "                         num_leaves=5, # Lebih kecil untuk mencegah overfitting awal\n",
    "                         learning_rate=0.05,\n",
    "                         n_estimators=720, # Jumlah pohon\n",
    "                         max_bin = 55, bagging_fraction = 0.8,\n",
    "                         bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                         feature_fraction_seed=9, bagging_seed=9,\n",
    "                         min_data_in_leaf =6, min_sum_hessian_in_leaf = 11,\n",
    "                         random_state=42) # Parameter ini hanya contoh, perlu tuning!\n",
    "\n",
    "score = rmsle_cv(lgbm)\n",
    "print(f\"\\nSkor CV (RMSLE) LightGBM: {score.mean():.4f} +/- {score.std():.4f}\")\n",
    "\n",
    "# --- Langkah 6: Hyperparameter Tuning (Dilewati dalam contoh ini) ---\n",
    "# Di sini Anda akan menggunakan Optuna atau GridSearchCV/RandomizedSearchCV\n",
    "# untuk mencari parameter terbaik berdasarkan skor CV.\n",
    "\n",
    "# --- Langkah 7: Ensembling (Contoh: Averaging Sederhana) ---\n",
    "# Kita bisa melatih beberapa model (misal: LGBM, XGBoost, Ridge)\n",
    "# dan merata-ratakan prediksinya. Untuk simplifikasi, kita hanya gunakan LGBM.\n",
    "# Dalam CV di atas, kita sudah dapat gambaran performa.\n",
    "\n",
    "# --- Langkah 8: Prediksi Akhir & Submission ---\n",
    "\n",
    "# Melatih model final pada seluruh data training\n",
    "# (Gunakan parameter terbaik hasil tuning jika ada)\n",
    "lgbm.fit(train_final.values, y_train)\n",
    "\n",
    "# Membuat prediksi pada data test\n",
    "lgbm_pred_log = lgbm.predict(test_final.values)\n",
    "\n",
    "# Mengembalikan ke skala asli (ingat kita pakai log1p)\n",
    "lgbm_pred = np.expm1(lgbm_pred_log)\n",
    "\n",
    "# Membuat file submission\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test_ID\n",
    "submission['SalePrice'] = lgbm_pred\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\nFile submission.csv telah dibuat.\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
