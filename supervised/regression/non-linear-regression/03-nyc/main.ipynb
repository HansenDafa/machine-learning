{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58bccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Langkah 1: Eksplorasi Data (EDA) & Pemahaman Masalah ---\n",
    "\n",
    "# Memuat Data (Gunakan nrows untuk membatasi ukuran memori!)\n",
    "# Ganti 'train.csv' dan 'test.csv' dengan nama file yang sesuai\n",
    "# Untuk demo, kita gunakan 1 juta baris data training\n",
    "try:\n",
    "    train_df = pd.read_csv('train.csv', nrows=1_000_000, parse_dates=['pickup_datetime'])\n",
    "    test_df = pd.read_csv('test.csv', parse_dates=['pickup_datetime']) # Test set biasanya lebih kecil\n",
    "except FileNotFoundError:\n",
    "    print(\"Pastikan file 'train.csv' dan 'test.csv' ada di direktori yang sama.\")\n",
    "    # Membuat data dummy jika file tidak ditemukan (HANYA UNTUK DEMO CODE AGAR JALAN)\n",
    "    print(\"Membuat data dummy...\")\n",
    "    data = {\n",
    "        'key': [f'key_{i}' for i in range(1000)],\n",
    "        'fare_amount': np.random.rand(1000) * 50 + 2.5,\n",
    "        'pickup_datetime': pd.to_datetime(['2010-01-01 12:00:00 UTC'] * 1000) + pd.to_timedelta(np.random.randint(0, 365*24*60*60, 1000), unit='s'),\n",
    "        'pickup_longitude': np.random.uniform(-74.05, -73.75, 1000),\n",
    "        'pickup_latitude': np.random.uniform(40.6, 40.9, 1000),\n",
    "        'dropoff_longitude': np.random.uniform(-74.05, -73.75, 1000),\n",
    "        'dropoff_latitude': np.random.uniform(40.6, 40.9, 1000),\n",
    "        'passenger_count': np.random.randint(1, 6, 1000)\n",
    "    }\n",
    "    train_df = pd.DataFrame(data)\n",
    "    test_data = data.copy()\n",
    "    del test_data['fare_amount'] # Test set tidak punya fare_amount\n",
    "    test_df = pd.DataFrame(test_data)\n",
    "\n",
    "\n",
    "print(f\"Ukuran data Train awal: {train_df.shape}\")\n",
    "print(f\"Ukuran data Test awal: {test_df.shape}\")\n",
    "print(\"\\nContoh data Train:\")\n",
    "print(train_df.head())\n",
    "\n",
    "# Analisis Target Variable ('fare_amount')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['fare_amount'], bins=100, kde=False)\n",
    "plt.title('Distribusi Fare Amount (Original)')\n",
    "plt.xlabel('Fare Amount ($)')\n",
    "plt.xlim(0, 100) # Batasi x-axis untuk visualisasi yang lebih baik\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStatistik Deskriptif Fare Amount:\")\n",
    "print(train_df['fare_amount'].describe())\n",
    "\n",
    "# --- Langkah 3 Awal: Pembersihan Data (Sangat Penting di sini!) ---\n",
    "\n",
    "# 1. Hapus baris dengan fare_amount <= 0\n",
    "print(f\"\\nJumlah baris sebelum filter fare_amount: {len(train_df)}\")\n",
    "train_df = train_df[train_df['fare_amount'] > 0]\n",
    "print(f\"Jumlah baris setelah filter fare_amount > 0: {len(train_df)}\")\n",
    "\n",
    "# 2. Hapus baris dengan koordinat tidak valid (di luar batas wajar NYC)\n",
    "min_lon, max_lon = -75, -72\n",
    "min_lat, max_lat = 40, 42\n",
    "train_df = train_df[\n",
    "    (train_df['pickup_longitude'].between(min_lon, max_lon)) &\n",
    "    (train_df['pickup_latitude'].between(min_lat, max_lat)) &\n",
    "    (train_df['dropoff_longitude'].between(min_lon, max_lon)) &\n",
    "    (train_df['dropoff_latitude'].between(min_lat, max_lat))\n",
    "]\n",
    "print(f\"Jumlah baris setelah filter koordinat: {len(train_df)}\")\n",
    "\n",
    "# 3. Hapus baris dengan passenger_count aneh (misal > 8 atau < 1)\n",
    "print(f\"\\nNilai unik passenger_count sebelum filter: {sorted(train_df['passenger_count'].unique())}\")\n",
    "train_df = train_df[(train_df['passenger_count'] >= 1) & (train_df['passenger_count'] <= 8)]\n",
    "print(f\"Jumlah baris setelah filter passenger_count: {len(train_df)}\")\n",
    "\n",
    "# 4. Hapus baris dengan data hilang (jika ada setelah load)\n",
    "print(f\"\\nJumlah NaN sebelum dropna: {train_df.isnull().sum().sum()}\")\n",
    "train_df.dropna(inplace=True)\n",
    "print(f\"Jumlah baris setelah dropna: {len(train_df)}\")\n",
    "\n",
    "# Simpan target variable (setelah cleaning)\n",
    "y_train = train_df['fare_amount']\n",
    "# Simpan key test set untuk submission\n",
    "test_key = test_df['key'] if 'key' in test_df.columns else None # Jika ada kolom 'key'\n",
    "\n",
    "# Gabungkan train (tanpa target) dan test untuk feature engineering\n",
    "# Hapus kolom target dari train_df SEBELUM menggabungkan\n",
    "train_features = train_df.drop(columns=['fare_amount', 'key'], errors='ignore') # Hapus key juga jika ada\n",
    "test_features = test_df.drop(columns=['key'], errors='ignore')\n",
    "ntrain = train_features.shape[0]\n",
    "\n",
    "all_features = pd.concat((train_features, test_features)).reset_index(drop=True)\n",
    "print(f\"\\nUkuran data gabungan untuk feature engineering: {all_features.shape}\")\n",
    "\n",
    "\n",
    "# --- Langkah 4: Feature Engineering (Kunci untuk dataset ini!) ---\n",
    "\n",
    "# Fungsi untuk menghitung jarak Haversine (jarak garis lurus di permukaan bola)\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    p = np.pi/180\n",
    "    a = 0.5 - np.cos((lat2-lat1)*p)/2 + np.cos(lat1*p) * np.cos(lat2*p) * (1-np.cos((lon2-lon1)*p))/2\n",
    "    return 12742 * np.arcsin(np.sqrt(a)) # 2*R*arcsin... R=6371 km\n",
    "\n",
    "# 1. Hitung Jarak Perjalanan\n",
    "all_features['distance_km'] = haversine_distance(\n",
    "    all_features['pickup_latitude'], all_features['pickup_longitude'],\n",
    "    all_features['dropoff_latitude'], all_features['dropoff_longitude']\n",
    ")\n",
    "\n",
    "# 2. Ekstrak Fitur dari pickup_datetime\n",
    "all_features['year'] = all_features['pickup_datetime'].dt.year\n",
    "all_features['month'] = all_features['pickup_datetime'].dt.month\n",
    "all_features['day'] = all_features['pickup_datetime'].dt.day\n",
    "all_features['dayofweek'] = all_features['pickup_datetime'].dt.dayofweek\n",
    "all_features['hour'] = all_features['pickup_datetime'].dt.hour\n",
    "# all_features['minute'] = all_features['pickup_datetime'].dt.minute # Mungkin tidak terlalu penting\n",
    "\n",
    "# 3. Hapus kolom asli yang tidak diperlukan lagi / tidak bisa dipakai model\n",
    "all_features.drop(['pickup_datetime', 'pickup_longitude', 'pickup_latitude',\n",
    "                   'dropoff_longitude', 'dropoff_latitude'], axis=1, inplace=True)\n",
    "\n",
    "print(\"\\nContoh data setelah Feature Engineering:\")\n",
    "print(all_features.head())\n",
    "print(f\"Bentuk data setelah Feature Engineering: {all_features.shape}\")\n",
    "\n",
    "\n",
    "# --- Langkah 3 Akhir: Preprocessing Sisa (Jika Perlu) ---\n",
    "# Dalam kasus ini, setelah feature engineering, sebagian besar fitur sudah numerik.\n",
    "# 'passenger_count' bisa dianggap numerik atau kategorikal. Kita biarkan numerik.\n",
    "# 'year', 'month', 'day', 'dayofweek', 'hour' juga numerik (ordinal).\n",
    "# Tidak ada encoding yang diperlukan di sini. Scaling mungkin diperlukan jika pakai model linear.\n",
    "\n",
    "\n",
    "# Pisahkan kembali data train dan test\n",
    "train_final = all_features[:ntrain]\n",
    "test_final = all_features[ntrain:]\n",
    "print(f\"\\nUkuran data Train Final: {train_final.shape}\")\n",
    "print(f\"Ukuran data Test Final: {test_final.shape}\")\n",
    "\n",
    "\n",
    "# --- Langkah 2 & 5: Strategi Validasi & Model Baseline (LightGBM) ---\n",
    "\n",
    "# Mendefinisikan fungsi evaluasi RMSE\n",
    "def rmse_cv(model):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42).get_n_splits(train_final.values)\n",
    "    # Gunakan neg_mean_squared_error, lalu akarkan dan balikkan tanda negatif\n",
    "    rmse = np.sqrt(-cross_val_score(model, train_final.values, y_train,\n",
    "                                     scoring=\"neg_mean_squared_error\", cv = kf, n_jobs=-1)) # n_jobs=-1 gunakan semua core\n",
    "    return(rmse)\n",
    "\n",
    "# Model LightGBM (Parameter awal)\n",
    "lgbm = lgb.LGBMRegressor(objective='regression_l1', # L1 (MAE) sering lebih robust thd outlier drpd L2 (MSE)\n",
    "                         metric='rmse', # Monitor RMSE selama training\n",
    "                         n_estimators=1000, # Jumlah pohon awal, bisa diatur dgn early stopping\n",
    "                         learning_rate=0.05,\n",
    "                         num_leaves=31, # Default\n",
    "                         max_depth=-1, # Default\n",
    "                         random_state=42,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "# Evaluasi dengan Cross-Validation\n",
    "# Catatan: CV pada 1 juta baris bisa memakan waktu. Anda bisa kurangi n_splits atau data\n",
    "# Jika Anda hanya ingin menjalankan kode tanpa menunggu lama, komentari bagian CV ini.\n",
    "print(\"\\nMemulai Cross Validation (bisa memakan waktu)...\")\n",
    "# score = rmse_cv(lgbm)\n",
    "# print(f\"Skor CV (RMSE) LightGBM: {score.mean():.4f} +/- {score.std():.4f}\")\n",
    "# --- Jika CV terlalu lama, lewati saja untuk demo ---\n",
    "print(\"Melewati Cross Validation untuk demo cepat.\")\n",
    "# ---\n",
    "\n",
    "# --- Langkah 6: Hyperparameter Tuning (Dilewati dalam contoh ini) ---\n",
    "# Gunakan Optuna/GridSearch/RandomSearch di sini.\n",
    "\n",
    "# --- Langkah 7: Ensembling (Dilewati dalam contoh ini) ---\n",
    "# Gabungkan prediksi dari LGBM, XGBoost, dll.\n",
    "\n",
    "# --- Langkah 8: Prediksi Akhir & Submission ---\n",
    "\n",
    "print(\"\\nMelatih model final pada seluruh data training...\")\n",
    "# Latih model pada seluruh data training (gunakan parameter terbaik jika ada tuning)\n",
    "# Tambahkan early stopping jika n_estimators besar\n",
    "# Untuk ini kita perlu validation set kecil atau gunakan fitur early stopping di CV\n",
    "# Cara sederhana: latih saja dengan n_estimators yang ditentukan\n",
    "lgbm.fit(train_final.values, y_train)\n",
    "\n",
    "print(\"Membuat prediksi pada data test...\")\n",
    "# Membuat prediksi pada data test\n",
    "predictions = lgbm.predict(test_final.values)\n",
    "# Pastikan tidak ada prediksi negatif (meskipun L1 harusnya mengurangi ini)\n",
    "predictions[predictions < 0] = 0\n",
    "\n",
    "# Membuat file submission\n",
    "submission = pd.DataFrame()\n",
    "# Pastikan test_key diambil dengan benar sebelumnya\n",
    "if test_key is not None:\n",
    "     submission['key'] = test_key\n",
    "else:\n",
    "     # Jika tidak ada 'key' di test set asli, buat index dummy\n",
    "     submission['key'] = test_final.index\n",
    "submission['fare_amount'] = predictions\n",
    "submission.to_csv('submission_taxi.csv', index=False)\n",
    "\n",
    "print(\"\\nFile submission_taxi.csv telah dibuat.\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
